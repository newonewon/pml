---
title: "PracticalMachineLearningProject"
author: "NEWONE"
date: "1 May 2016"
output: html_document
---
# Introduction

These are the files produced during a homework assignment of Coursera's MOOC Practical Machine Learning from Johns Hopkins University. Here is the introduction of the exercise:

"Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement-a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).""

#Data Sources
The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project comes from this original source: http://groupware.les.inf.puc-rio.br/har. If you use the document you create for this class for any purpose please cite them as they have been very generous in allowing their data to be used for this kind of assignment.

Please Note that I the code I use loads the data directly from the URL provided, so that you are not required to download the file to your environment. Please customize the code to your specific needs

# Reproduceablity
In order to reproduce the same results, you need a certain set of packages, as well as setting a pseudo random seed equal to the one I used. *Note:To install, for instance, the caret package in R, run this command: install.packages("caret")

The following Libraries were used for this project, which you should install - if not done yet - and load on your working environment.

1. caret
2. randomForest

# Getting the data
In this section, load the data and the 20 cases that will be submitted to coursera.


```{r}
library(caret)

rm(list = ls())
if (!file.exists("pml-training.csv")) {
  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv")
}
if (!file.exists("pml-testing.csv")) {
  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv")
}
submit <- read.csv("pml-testing.csv", sep = ",", na.strings = c("", "NA"))
data <- read.csv("pml-training.csv", sep = ",", na.strings = c("", "NA"))

```

# Cleanup the data

Removing columns containing NAs and removing features that are not in the submit set. The features containing NAs are the variance, mean and stddev within each window for each feature.Also removing the first seven features since they are related to the time-series or are not numeric.

```{r, echo=FALSE}
# Remove columns full of NAs.
features <- names(submit[,colSums(is.na(submit)) == 0])[8:59]
# Only use features used in submit cases.
data <- data[,c(features,"classe")]
submit <- submit[,c(features,"problem_id")]
```

#Partioning the training set into two

Next,Partioning Training data set into two data sets,75% for training, 25% of the dataset for testing after the final model is constructed.


```{r, echo=FALSE}
set.seed(916)
inTrain = createDataPartition(data$classe, p = 0.75, list = F)
training = data[inTrain,]
testing = data[-inTrain,]

```


# Choosing features
Dropping features with high correlation (>90%).

```{r, echo=FALSE}
outcome = which(names(training) == "classe")
highCorrCols = findCorrelation(abs(cor(training[,-outcome])),0.90)
highCorrFeatures = names(training)[highCorrCols]
training = training[,-highCorrCols]
outcome = which(names(training) == "classe")

```

The features with high correlation are accel_belt_z, roll_belt, accel_belt_y, accel_belt_x, gyros_arm_y, gyros_forearm_z, and gyros_dumbbell_x.

# Detecting the Importance of Features
We use the random forest to detect the most important features. Below is the feature plot for the 4 important features. 

```{r, echo=FALSE}
library(randomForest)

fsRF = randomForest(training[,-outcome], training[,outcome], importance = T)
rfImp = data.frame(fsRF$importance)
impFeatures = order(-rfImp$MeanDecreaseGini)
inImp = createDataPartition(data$classe, p = 0.05, list = F)
featurePlot(training[inImp,impFeatures[1:4]],training$classe[inImp], plot = "density",scales = list(x = list(relation="free"),y = list(relation="free")),adjust = 1.5,pch = "|",
                  layout = c(4, 1),
                  auto.key = list(columns = 3))
```

The most important features are:pitch_belt,yaw_belt,total_accel_belt,gyros_belt_x

#Training
 Train using the random forest and k-nearest neighbors for comparison.

```{r}
ctrlKNN = trainControl(method = "adaptive_cv")
modelKNN = train(classe ~ ., training, method = "knn", trControl = ctrlKNN)
ctrlRF = trainControl(method = "oob")
modelRF = train(classe ~ ., training, method = "rf", ntree = 200, trControl = ctrlRF)
resultsKNN = data.frame(modelKNN$results)
resultsRF = data.frame(modelRF$results)

```

# Testing Out-of-sample error
The random forest will give a larger accuracy compared to k-nearest neighbors. Here,we compare each model using the test set outcomes.


```{r}
fitKNN = predict(modelKNN, testing)
fitRF = predict(modelRF, testing)

print(confusionMatrix(fitKNN, testing$classe), digits=4)

print(confusionMatrix(fitRF, testing$classe), digits=4)

```

The random forest fit is clearly more accurate than the k-nearest neighbors method with 99% accuracy.

Now using the random forest model to predict on the 20 cases submitted to coursera.

```{r}
print(predict(modelRF, submit))
```
